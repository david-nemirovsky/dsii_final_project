---
title: "Final Project"
author: "David Nemirovsky & Jared Klug"
output: github_document
date: 5/13/21
--- 

```{r setup, include = FALSE}
library(tidyverse)
library(caret)
library(ISLR)
library(e1071)
library(gtsummary)
library(vip)
library(patchwork)
library(ranger)
library(gbm)
library(visdat)

knitr::opts_chunk$set(
  fig.align = "center",
  fig.width = 7,
  fig.asp = .6,
  out.width = "80%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d

set.seed(37564)
```

## **EDA**

```{r eda, message = F, warning = F}
titanic_df = 
  read_csv("./data/train.csv") %>% 
  janitor::clean_names() %>% 
  mutate(survived = fct_recode(as.factor(survived), yes = "1", no = "0"), 
         pclass = as.factor(pclass), 
         sex = as.factor(sex), 
         embarked = as.factor(embarked))

train_df = 
  titanic_df %>% 
  select(-c(ticket, cabin, name, passenger_id)) %>% 
  drop_na()

#Missing data eda
train_nas = 
  titanic_df %>% 
  select(-c(ticket, cabin, name, passenger_id))

vis_miss(train_nas)

miss_surv = train_nas %>% 
  filter(is.na(age)) %>% 
  group_by(survived) %>% 
  summarise(count = n())

miss_surv

all_surv = 
#calc percentage of NA ages that survived

tbl_summary(train_df)

featurePlot(x = select(mutate(train_df, 
                              pclass = as.numeric(pclass), 
                              sex = as.numeric(sex),
                              embarked = as.numeric(embarked)),
                       pclass:embarked), 
            y = train_df$survived,
            scales = list(x = list(relation = "free"), 
                          y = list(relation = "free")),
            plot = "density", 
            auto.key = list(columns = 2))

train_df %>% 
  ggplot(aes(x = age, fill = survived)) +
  geom_density(alpha = 0.75) + 
  facet_grid(sex ~ pclass)

train_df %>% 
  filter(fare < 100) %>% 
  ggplot(aes(x = fare, fill = survived)) +
  geom_density(alpha = 0.75) + 
  facet_grid(sex ~ pclass)

train_df %>% 
  #filter(fare < 100) %>% 
  ggplot(aes(x = age, y = fare, color = survived)) +
  geom_point(alpha = 0.75) + 
  facet_grid(sex ~ pclass)

train_df %>% 
  ggplot(aes(x = age, fill = survived)) + 
  geom_density(alpha = 0.75) + 
  facet_grid(sex ~ embarked)

train_df %>% 
  #filter(fare < 100) %>% 
  ggplot(aes(x = age, y = fare, color = survived)) +
  geom_point(alpha = 0.75) + 
  facet_grid(sex ~ embarked)
```

## **Model Training**

```{r models, message = F, warning = F}
set.seed(37564)

ctrl = trainControl(method = "repeatedcv", summaryFunction = twoClassSummary, classProbs = T, number = 10, repeats = 5)

mod_glm = train(survived ~ .,
                na.action = na.exclude, 
                data = train_df, 
                method = "glm", 
                family = "binomial", 
                metric = "ROC", 
                trControl = ctrl)
summary(mod_glm)

mod_enet = train(survived ~ .,
                 na.action = na.exclude, 
                 data = train_df, 
                 method = "glmnet", 
                 family = "binomial", 
                 metric = "ROC", 
                 tuneGrid = expand.grid(alpha = seq(0, 0.5, length = 6), 
                                        lambda = exp(seq(-4, -8, length = 50))),
                 trControl = ctrl)
tuning_plot_enet = 
  ggplot(mod_enet, highlight = T) + 
  ggtitle("Elastic Net") +
  theme(plot.title = element_text(hjust = 0.5))
mod_enet$bestTune

mod_mars = train(survived ~ ., 
                 na.action = na.exclude, 
                 data = train_df, 
                 method = "earth",
                 tuneGrid = expand.grid(degree = 1:3, nprune = 5:15), 
                 metric = "ROC", 
                 trControl = ctrl)
tuning_plot_mars = 
  ggplot(mod_mars, highlight = T) + 
  ggtitle("MARS") +
  theme(plot.title = element_text(hjust = 0.5))
mod_mars$bestTune

mod_knn = train(survived ~ .,
                na.action = na.exclude, 
                data = train_df, 
                method = "knn",
                metric = "ROC", 
                preProcess = c("center","scale"),
                tuneGrid = data.frame(k = seq(1, 30, by = 1)), 
                trControl = ctrl)
tuning_plot_knn = 
  ggplot(mod_knn, highlight = T) + 
  ggtitle("KNN") +
  theme(plot.title = element_text(hjust = 0.5))
mod_knn$bestTune

mod_boost = train(survived ~ .,
                  na.action = na.exclude,
                  data = train_df,
                  method = "gbm",
                  distribution = "adaboost",
                  tuneGrid = expand.grid(n.trees = c(2000, 3000),
                                         interaction.depth = 2:7,
                                         shrinkage = c(0.005, 0.007, 0.009), 
                                         n.minobsinnode = 1),
                  metric = "ROC",
                  trControl = ctrl,
                  verbose = F)
tuning_plot_boost = 
  ggplot(mod_boost, highlight = T) + 
  ggtitle("Boosting") +
  theme(plot.title = element_text(hjust = 0.5))
mod_boost$bestTune

mod_svm = train(survived ~ .,
                na.action = na.exclude,
                data = train_df,
                preProcess = c("scale", "center"),
                method = "svmLinear",
                tuneGrid = expand.grid(C = exp(seq(-2,3, len = 20))),
                metric = "ROC",
                trControl = ctrl
)

tuning_plot_svm_linear = 
  ggplot(mod_svm, highlight = T) + 
  ggtitle("SVM Linear") +
  theme(plot.title = element_text(hjust = 0.5))
mod_svm$bestTune

mod_svm_radial = train(survived ~ .,
                na.action = na.exclude,
                data = train_df,
                preProcess = c("scale", "center"),
                method = "svmRadialSigma",
                tuneGrid = expand.grid(C = exp(seq(-2,3, len = 10)),
                                       sigma = exp(seq(-8,0,len=10))),
                metric = "ROC",
                trControl = ctrl
)

tuning_plot_svm_radial = 
  ggplot(mod_svm_radial, highlight = T) + 
  ggtitle("SVM Radial") +
  theme(plot.title = element_text(hjust = 0.5))
mod_svm_radial$bestTune

(tuning_plot_enet + tuning_plot_mars + tuning_plot_knn) / tuning_plot_boost

res = resamples(list(GLM = mod_glm, ENET = mod_enet, MARS = mod_mars, KNN = mod_knn, BOOST = mod_boost, SVM_lin = mod_svm, SVM_rad = mod_svm_radial ))
summary(res)
bwplot(res, metric = "ROC", main = "ROC for Repeated 10-Fold CV Using Various Models")
```

## **Variable Importance**

```{r vip, message = F, warning = F}
set.seed(37564)

#vip(mod_glm, 
#    method = "permute", 
#    train = train_df,
#    target = "survived",
#    metric = "auc",
#    reference_class = c("yes", "no"),
#    nsim = 1000,
#    pred_wrapper = predict,
#    geom = "boxplot", 
#    all_permutations = T,
#    mapping = aes_string(fill = "Variable", alpha = 0.75))

#vip(mod_enet, 
#    method = "permute", 
#    train = train_df,
#    target = "survived",
#    metric = "auc",
#    reference_class = c("yes", "no"),
#    nsim = 1000,
#    pred_wrapper = predict,
#    geom = "boxplot", 
#    all_permutations = T,
#    mapping = aes_string(fill = "Variable", alpha = 0.75))

vip(mod_mars, 
    method = "permute", 
    train = train_df,
    target = "survived",
    metric = "auc",
    reference_class = c("yes", "no"),
    nsim = 1000,
    pred_wrapper = predict,
    geom = "boxplot", 
    all_permutations = T,
    mapping = aes_string(fill = "Variable", alpha = 0.75))

#vip(mod_knn, 
#    method = "permute", 
#    train = train_df,
#    target = "survived",
#    metric = "auc",
#    reference_class = c("yes", "no"),
#    nsim = 1000,
#    pred_wrapper = predict,
#    geom = "boxplot", 
#    all_permutations = T,
#    mapping = aes_string(fill = "Variable", alpha = 0.75))

vip(mod_boost, 
    method = "permute", 
    train = train_df,
    target = "survived",
    metric = "auc",
    reference_class = c("yes", "no"),
    nsim = 200,
    pred_wrapper = predict,
    geom = "boxplot", 
    all_permutations = T,
    mapping = aes_string(fill = "Variable", alpha = 0.75))
```

## test/kaggle output
```{r}
train_df = 
  titanic_df %>% 
  select(-c(ticket, cabin, name, passenger_id)) %>% 
  drop_na()

test_df = read_csv("./data/test.csv") %>% 
  janitor::clean_names() %>% 
  mutate(pclass = as.factor(pclass), 
         sex = as.factor(sex), 
         embarked = as.factor(embarked)) %>% 
  select(-c(ticket, cabin, name, passenger_id))
  

```

